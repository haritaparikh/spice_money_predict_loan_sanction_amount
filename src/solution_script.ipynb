{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import r2_score\n",
    "import time\n",
    "import os\n",
    "import pickle \n",
    "import json\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_key = \"agent_id\"\n",
    "timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "data_path = \"../data\"\n",
    "processed_data_path = os.path.join(data_path, \"processed_data\")\n",
    "output_path = os.path.join(\"../output\")\n",
    "model_path = os.path.join(output_path, \"model\", \"artifact\")\n",
    "metrics_path = os.path.join(output_path, \"model\", \"metrics\")\n",
    "feature_importance_path = os.path.join(output_path, \"model\", \"feature_importance\")\n",
    "predict_path = os.path.join(output_path, \"predictions\")\n",
    "if not os.path.exists(model_path):\n",
    "    os.makedirs(model_path)  \n",
    "if not os.path.exists(predict_path):\n",
    "    os.makedirs(predict_path)  \n",
    "if not os.path.exists(metrics_path):\n",
    "    os.makedirs(metrics_path) \n",
    "if not os.path.exists(feature_importance_path):\n",
    "    os.makedirs(feature_importance_path)\n",
    "    \n",
    "def save_pickle_model(model_parameters, \n",
    "                      model_path, \n",
    "                      file_opts):\n",
    "    # Save the model to disk\n",
    "    with open(model_path, \n",
    "              file_opts) as pickle_out:\n",
    "        pickle.dump(model_parameters, \n",
    "                    pickle_out)\n",
    "\n",
    "def load_pickle_model(model_path, \n",
    "                      file_opts):\n",
    "    # Load the model from disk\n",
    "    with open(model_path, \n",
    "              file_opts) as pickle_in:\n",
    "        return pickle.load(pickle_in)\n",
    "    \n",
    "def save_dict_to_json(dictionary, path, file_opts):\n",
    "    # save model metrics\n",
    "    with open(path, file_opts) as outfile:\n",
    "        json.dump(dictionary, outfile) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pd.read_csv(os.path.join(processed_data_path, \n",
    "                                   \"x_train.csv\"))\n",
    "x_val = pd.read_csv(os.path.join(processed_data_path, \n",
    "                                 \"x_val.csv\"))\n",
    "y_train = pd.read_csv(os.path.join(processed_data_path, \n",
    "                                   \"y_train.csv\"))\n",
    "y_val = pd.read_csv(os.path.join(processed_data_path, \n",
    "                                 \"y_val.csv\"))\n",
    "x_test = pd.read_csv(os.path.join(processed_data_path, \n",
    "                                  \"x_test.csv\"))\n",
    "del x_train[primary_key]\n",
    "del x_val[primary_key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35692, 92)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForest regressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed: 41.4min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed: 178.6min\n",
      "[Parallel(n_jobs=-1)]: Done 324 out of 324 | elapsed: 359.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6h 19min 52s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=RandomForestRegressor(), n_jobs=-1,\n",
       "             param_grid={'max_depth': [5, 10, 15],\n",
       "                         'max_features': ['auto', 'sqrt'],\n",
       "                         'min_samples_leaf': [5, 10, 15],\n",
       "                         'min_samples_split': [5, 10, 15],\n",
       "                         'n_estimators': [100, 500]},\n",
       "             scoring='neg_mean_squared_error', verbose=2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "params = {'n_estimators':[100, 500],\n",
    "          'min_samples_split':[5, 10, 15],\n",
    "          'min_samples_leaf':[5, 10, 15],\n",
    "         'max_depth': [5, 10, 15],\n",
    "         'max_features': ['auto', 'sqrt']}\n",
    "\n",
    "model = RandomForestRegressor()\n",
    "rf_model = GridSearchCV(model,\n",
    "                         cv=3,\n",
    "                         param_grid=params,\n",
    "                         n_jobs=-1,\n",
    "                         verbose=2,\n",
    "                         scoring='neg_mean_squared_error')\n",
    "\n",
    "rf_model.fit(x_train,\n",
    "             y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving model to disk\n",
    "\n",
    "save_pickle_model(rf_model.best_estimator_, os.path.join(\n",
    "    model_path, \"rf_tuned_model.pickle\"), \"wb\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 8.32 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train': {'r2_score': 92.17, 'rmse_train': 2.22},\n",
       " 'val': {'r2_score': 85.96, 'rmse_val': 3.91}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# predictions and scoring\n",
    "\n",
    "rf_model = load_pickle_model(os.path.join(\n",
    "    model_path, \"rf_tuned_model.pickle\"), \"rb\")\n",
    "\n",
    "# r2_score\n",
    "rf_train_predicted = rf_model.predict(x_train)\n",
    "rf_score_train = round(max(0, 100)*r2_score(y_train.values.ravel(), \n",
    "                                      rf_train_predicted),2)\n",
    "rf_val_predicted = rf_model.predict(x_val)\n",
    "rf_score_val = round(max(0, 100)*r2_score(y_val, \n",
    "                                    rf_val_predicted),2)\n",
    "# rmse\n",
    "rmse_train =  round(mean_squared_error(y_train, rf_train_predicted),2)\n",
    "rmse_val = round(mean_squared_error(y_val, rf_val_predicted),2)\n",
    "\n",
    "rf_metric = {}\n",
    "rf_metric[\"train\"]={}\n",
    "rf_metric[\"val\"]={}\n",
    "rf_metric[\"train\"][\"r2_score\"] = rf_score_train\n",
    "rf_metric[\"val\"][\"r2_score\"] = rf_score_val\n",
    "rf_metric[\"train\"][\"rmse_train\"] = rmse_train\n",
    "rf_metric[\"val\"][\"rmse_val\"] = rmse_val\n",
    "\n",
    "save_dict_to_json(rf_metric, os.path.join(\n",
    "    metrics_path, 'rf_metric.json'), 'w')\n",
    "rf_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = {} \n",
    "for feature, importance in zip(x_train.columns, rf_model.feature_importances_):\n",
    "    feats[feature] = importance \n",
    "\n",
    "importances = pd.DataFrame.from_dict(feats, orient='index').rename(columns={0: 'Gini-importance'})\n",
    "feature_importances = importances.sort_values(by='Gini-importance', ascending=False).reset_index()\n",
    "\n",
    "feature_importances.to_csv(os.path.join(feature_importance_path, \n",
    "                                     \"feature_importances__%s.csv\"%timestr),\n",
    "                        index=False)\n",
    "\n",
    "#feature_importances.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pk_predict = x_test[primary_key]\n",
    "x_predict = x_test.drop([primary_key],1)\n",
    "\n",
    "predicted = rf_model.predict(x_predict)\n",
    "predict_df = pd.DataFrame(predicted, \n",
    "                          columns = [\"business_risk\"])\n",
    "\n",
    "output_dataframe = pd.merge(x_pk_predict, \n",
    "                            predict_df, \n",
    "                            how=\"left\", \n",
    "                            left_index=True, \n",
    "                            right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dataframe.to_csv(os.path.join(predict_path, \n",
    "                                     \"rf_model_%s.csv\"%timestr),\n",
    "                        index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
