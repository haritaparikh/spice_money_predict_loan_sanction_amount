{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import r2_score\n",
    "import time\n",
    "import os\n",
    "import pickle \n",
    "import json\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_key = \"agent_id\"\n",
    "timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "data_path = \"../data\"\n",
    "processed_data_path = os.path.join(data_path, \"processed_data\")\n",
    "output_path = os.path.join(\"../output\")\n",
    "model_path = os.path.join(output_path, \"model\", \"artifact\")\n",
    "metrics_path = os.path.join(output_path, \"model\", \"metrics\")\n",
    "feature_importance_path = os.path.join(output_path, \"model\", \"feature_importance\")\n",
    "predict_path = os.path.join(output_path, \"predictions\")\n",
    "if not os.path.exists(model_path):\n",
    "    os.makedirs(model_path)  \n",
    "if not os.path.exists(predict_path):\n",
    "    os.makedirs(predict_path)  \n",
    "if not os.path.exists(metrics_path):\n",
    "    os.makedirs(metrics_path) \n",
    "if not os.path.exists(feature_importance_path):\n",
    "    os.makedirs(feature_importance_path)\n",
    "    \n",
    "def save_pickle_model(model_parameters, \n",
    "                      model_path, \n",
    "                      file_opts):\n",
    "    # Save the model to disk\n",
    "    with open(model_path, \n",
    "              file_opts) as pickle_out:\n",
    "        pickle.dump(model_parameters, \n",
    "                    pickle_out)\n",
    "\n",
    "def load_pickle_model(model_path, \n",
    "                      file_opts):\n",
    "    # Load the model from disk\n",
    "    with open(model_path, \n",
    "              file_opts) as pickle_in:\n",
    "        return pickle.load(pickle_in)\n",
    "    \n",
    "def save_dict_to_json(dictionary, path, file_opts):\n",
    "    # save model metrics\n",
    "    with open(path, file_opts) as outfile:\n",
    "        json.dump(dictionary, outfile) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pd.read_csv(os.path.join(processed_data_path, \n",
    "                                   \"x_train.csv\"))\n",
    "x_val = pd.read_csv(os.path.join(processed_data_path, \n",
    "                                 \"x_val.csv\"))\n",
    "y_train = pd.read_csv(os.path.join(processed_data_path, \n",
    "                                   \"y_train.csv\"))\n",
    "y_val = pd.read_csv(os.path.join(processed_data_path, \n",
    "                                 \"y_val.csv\"))\n",
    "x_test = pd.read_csv(os.path.join(processed_data_path, \n",
    "                                  \"x_test.csv\"))\n",
    "del x_train[primary_key]\n",
    "del x_val[primary_key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35692, 92)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'n_estimators':[500, 1000],\n",
    "          'min_samples_split':[2,5],\n",
    "          'min_samples_leaf':[2, 5],\n",
    "         'max_depth': [15, 20, 25],\n",
    "         'max_features': ['auto']}\n",
    "\n",
    "model = RandomForestRegressor()\n",
    "rf_model = GridSearchCV(model,\n",
    "                         cv=3,\n",
    "                         param_grid=params,\n",
    "                         n_jobs=-1,\n",
    "                         verbose=2,\n",
    "                         scoring='neg_mean_squared_error')\n",
    "\n",
    "rf_model.fit(x_train,\n",
    "             y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving model to disk\n",
    "\n",
    "save_pickle_model(rf_model.best_estimator_, os.path.join(\n",
    "    model_path, \"rf_tuned_model.pickle\"), \"wb\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions and scoring\n",
    "\n",
    "rf_model = load_pickle_model(os.path.join(\n",
    "    model_path, \"rf_tuned_model.pickle\"), \"rb\")\n",
    "\n",
    "# r2_score\n",
    "rf_train_predicted = rf_model.predict(x_train)\n",
    "rf_score_train = round(max(0, 100)*r2_score(y_train.values.ravel(), \n",
    "                                      rf_train_predicted),2)\n",
    "rf_val_predicted = rf_model.predict(x_val)\n",
    "rf_score_val = round(max(0, 100)*r2_score(y_val, \n",
    "                                    rf_val_predicted),2)\n",
    "# rmse\n",
    "rmse_train =  round(mean_squared_error(y_train, rf_train_predicted),2)\n",
    "rmse_val = round(mean_squared_error(y_val, rf_val_predicted),2)\n",
    "\n",
    "rf_metric = {}\n",
    "rf_metric[\"train\"]={}\n",
    "rf_metric[\"val\"]={}\n",
    "rf_metric[\"train\"][\"r2_score\"] = rf_score_train\n",
    "rf_metric[\"val\"][\"r2_score\"] = rf_score_val\n",
    "rf_metric[\"train\"][\"rmse_train\"] = rmse_train\n",
    "rf_metric[\"val\"][\"rmse_val\"] = rmse_val\n",
    "\n",
    "save_dict_to_json(rf_metric, os.path.join(\n",
    "    metrics_path, 'rf_metric.json'), 'w')\n",
    "rf_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForest regressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model development\n",
    "\n",
    "rf_model = RandomForestRegressor()\n",
    "rf_model.fit(x_train,\n",
    "             y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf_model.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving model to disk\n",
    "\n",
    "save_pickle_model(rf_model, os.path.join(\n",
    "    model_path, \"rf_model.pickle\"), \"wb\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions and scoring\n",
    "\n",
    "rf_model = load_pickle_model(os.path.join(\n",
    "    model_path, \"rf_model.pickle\"), \"rb\")\n",
    "\n",
    "# r2_score\n",
    "rf_train_predicted = rf_model.predict(x_train)\n",
    "rf_score_train = round(max(0, 100)*r2_score(y_train.values.ravel(), \n",
    "                                      rf_train_predicted),2)\n",
    "rf_val_predicted = rf_model.predict(x_val)\n",
    "rf_score_val = round(max(0, 100)*r2_score(y_val, \n",
    "                                    rf_val_predicted),2)\n",
    "# rmse\n",
    "rmse_train =  round(mean_squared_error(y_train, rf_train_predicted),2)\n",
    "rmse_val = round(mean_squared_error(y_val, rf_val_predicted),2)\n",
    "\n",
    "rf_metric = {}\n",
    "rf_metric[\"train\"]={}\n",
    "rf_metric[\"val\"]={}\n",
    "rf_metric[\"train\"][\"r2_score\"] = rf_score_train\n",
    "rf_metric[\"val\"][\"r2_score\"] = rf_score_val\n",
    "rf_metric[\"train\"][\"rmse_train\"] = rmse_train\n",
    "rf_metric[\"val\"][\"rmse_val\"] = rmse_val\n",
    "\n",
    "save_dict_to_json(rf_metric, os.path.join(\n",
    "    metrics_path, 'rf_metric.json'), 'w')\n",
    "rf_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = {} \n",
    "for feature, importance in zip(x_train.columns, rf_model.feature_importances_):\n",
    "    feats[feature] = importance \n",
    "\n",
    "importances = pd.DataFrame.from_dict(feats, orient='index').rename(columns={0: 'Gini-importance'})\n",
    "feature_importances = importances.sort_values(by='Gini-importance', ascending=False).reset_index()\n",
    "\n",
    "feature_importances.to_csv(os.path.join(feature_importance_path, \n",
    "                                     \"feature_importances__%s.csv\"%timestr),\n",
    "                        index=False)\n",
    "\n",
    "#feature_importances.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest: Using features with more than 1% Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_features_list = feature_importances[\"index\"].head(10)\n",
    "keep_features_list\n",
    "x_train_imp = x_train[keep_features_list]\n",
    "x_val_imp  = x_train[keep_features_list]\n",
    "\n",
    "# model development\n",
    "\n",
    "rf_model_imp = RandomForestRegressor()\n",
    "rf_model_imp.fit(x_train,\n",
    "             y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving model to disk\n",
    "\n",
    "save_pickle_model(rf_model_imp, os.path.join(\n",
    "    model_path, \"rf_model_imp.pickle\"), \"wb\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions and scoring\n",
    "\n",
    "rf_model_imp = load_pickle_model(os.path.join(\n",
    "    model_path, \"rf_model_imp.pickle\"), \"rb\")\n",
    "\n",
    "rf_imp_train_predicted = rf_model_imp.predict(x_train)\n",
    "rf_imp_score_train = max(0, 100)*r2_score(y_train.values.ravel(), \n",
    "                                      rf_imp_train_predicted)\n",
    "rf_imp_val_predicted = rf_model_imp.predict(x_val)\n",
    "rf_imp_score_val = max(0, 100)*r2_score(y_val, \n",
    "                                    rf_imp_val_predicted)\n",
    "\n",
    "# rmse\n",
    "rf_imp_rmse_train =  round(mean_squared_error(y_train, rf_imp_train_predicted),2)\n",
    "rf_imp_rmse_val = round(mean_squared_error(y_val, rf_imp_val_predicted),2)\n",
    "\n",
    "rf_imp_metric = {}\n",
    "rf_imp_metric[\"train\"]={}\n",
    "rf_imp_metric[\"val\"]={}\n",
    "rf_imp_metric[\"train\"][\"r2_score\"] = rf_imp_score_train\n",
    "rf_imp_metric[\"val\"][\"r2_score\"] = rf_imp_score_val\n",
    "rf_imp_metric[\"train\"][\"rmse_train\"] = rf_imp_rmse_train\n",
    "rf_imp_metric[\"val\"][\"rmse_val\"] = rf_imp_rmse_val\n",
    "\n",
    "\n",
    "save_dict_to_json(rf_imp_metric, os.path.join(\n",
    "    metrics_path, 'rf_imp_metric.json'), 'w')\n",
    "rf_imp_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RF_PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=20)\n",
    "x_train = pca.fit_transform(x_train)\n",
    "x_val = pca.transform(x_val)\n",
    "test_pk = x_test[primary_key]\n",
    "del x_test[primary_key]\n",
    "x_test = pca.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save(\"../data/processed_data/x_train.npy\", x_train)\n",
    "# np.save(\"../data/processed_data/x_test.npy\", x_test)\n",
    "# np.save(\"../data/processed_data/x_val.npy\", x_val)\n",
    "# np.save(\"../data/processed_data/y_train.npy\", y_train)\n",
    "# np.save(\"../data/processed_data/y_test.npy\", y_test)\n",
    "# np.save(\"../data/processed_data/y_val.npy\", y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train = np.load(\"../data/processed_data/x_train.npy\")\n",
    "# x_val = np.load(\"../data/processed_data/x_val.npy\")\n",
    "# y_train = np.load(\"../data/processed_data/y_train.npy\")\n",
    "# y_val = np.load(\"../data/processed_data/y_val.npy\")\n",
    "# x_test = np.load(\"../data/processed_data/x_test.npy\")\n",
    "# y_test = np.load(\"../data/processed_data/y_test.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pca_model = RandomForestRegressor()\n",
    "rf_pca_model.fit(x_train,\n",
    "             y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pickle_model(rf_pca_model, os.path.join(\n",
    "    model_path, \"rf_pca_model.pickle\"), \"wb\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions and scoring\n",
    "\n",
    "rf_pca_model = load_pickle_model(os.path.join(\n",
    "    model_path, \"rf_pca_model.pickle\"), \"rb\")\n",
    "\n",
    "# r2_score\n",
    "rf_pca_train_predicted = rf_pca_model.predict(x_train)\n",
    "rf_pca_score_train = round(max(0, 100)*r2_score(y_train.values.ravel(), \n",
    "                                      rf_pca_train_predicted),2)\n",
    "rf_pca_val_predicted = rf_pca_model.predict(x_val)\n",
    "rf_pca_score_val = round(max(0, 100)*r2_score(y_val, \n",
    "                                    rf_pca_val_predicted),2)\n",
    "# rmse\n",
    "rf_pca_rmse_train =  round(mean_squared_error(y_train, rf_pca_train_predicted),2)\n",
    "rf_pca_rmse_val = round(mean_squared_error(y_val, rf_pca_val_predicted),2)\n",
    "\n",
    "rf_pca_metric = {}\n",
    "rf_pca_metric[\"train\"]={}\n",
    "rf_pca_metric[\"val\"]={}\n",
    "rf_pca_metric[\"train\"][\"r2_score\"] = rf_pca_score_train\n",
    "rf_pca_metric[\"val\"][\"r2_score\"] = rf_pca_score_val\n",
    "rf_pca_metric[\"train\"][\"rmse_train\"] = rf_pca_rmse_train\n",
    "rf_pca_metric[\"val\"][\"rmse_val\"] = rf_pca_rmse_val\n",
    "\n",
    "save_dict_to_json(rf_pca_metric, os.path.join(\n",
    "    metrics_path, 'rf_pca_metric.json'), 'w')\n",
    "rf_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GradientBoosting Regressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model development\n",
    "\n",
    "# params = {'n_estimators':[100, 500],\n",
    "#         'learning_rate':[0.01, 0.001],\n",
    "#         'min_samples_leaf':[1,10,100],\n",
    "#         'min_samples_split': [5, 10],\n",
    "#          'tol': [0.001, 0.0001]}\n",
    "\n",
    "\n",
    "gb_model = GradientBoostingRegressor()\n",
    "# gb_model = GridSearchCV(model,\n",
    "#                          cv=10,\n",
    "#                          param_grid=params,\n",
    "#                          n_jobs=-1,\n",
    "#                          verbose=5,\n",
    "#                          scoring='neg_mean_absolute_error')\n",
    "gb_model.fit(x_train,\n",
    "             y_train.values.ravel())\n",
    "# gb_model.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving model to disk\n",
    "\n",
    "save_pickle_model(gb_model, os.path.join(\n",
    "    model_path, \"gb_model.pickle\"), \"wb\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions and scoring\n",
    "\n",
    "gbm_train_predicted = gb_model.predict(x_train)\n",
    "gbm_score_train = max(0, 100)*r2_score(y_train.values.ravel(), \n",
    "                                       gbm_train_predicted)\n",
    "gbm_val_predicted = gb_model.predict(x_val)\n",
    "gbm_score_val = max(0, 100)*r2_score(y_val, \n",
    "                                     gbm_val_predicted)\n",
    "# rmse\n",
    "gbm_rmse_train =  round(mean_squared_error(y_train, gbm_train_predicted),2)\n",
    "gbm_rmse_val = round(mean_squared_error(y_val, gbm_val_predicted),2)\n",
    "\n",
    "gbm_metric = {}\n",
    "gbm_metric[\"train\"]={}\n",
    "gbm_metric[\"val\"]={}\n",
    "gbm_metric[\"train\"][\"r2_score\"] = gbm_score_train\n",
    "gbm_metric[\"val\"][\"r2_score\"] = gbm_score_val\n",
    "gbm_metric[\"train\"][\"rmse_train\"] = gbm_rmse_train\n",
    "gbm_metric[\"val\"][\"rmse_val\"] = gbm_rmse_val\n",
    "save_dict_to_json(gbm_metric, os.path.join(\n",
    "    metrics_path, 'gbm_metric.json'), 'w')\n",
    "gbm_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = {} \n",
    "for feature, importance in zip(x_train.columns, gb_model.feature_importances_):\n",
    "    feats[feature] = importance \n",
    "\n",
    "importances = pd.DataFrame.from_dict(feats, orient='index').rename(columns={0: 'Gini-importance'})\n",
    "feature_importances = importances.sort_values(by='Gini-importance', ascending=False).reset_index()\n",
    "\n",
    "feature_importances.to_csv(os.path.join(feature_importance_path, \n",
    "                                     \"feature_importances__%s.csv\"%timestr),\n",
    "                        index=False)\n",
    "\n",
    "feature_importances.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_features_list = feature_importances[\"index\"].head(15)\n",
    "keep_features_list\n",
    "x_train_imp = x_train[keep_features_list]\n",
    "x_val_imp  = x_train[keep_features_list]\n",
    "\n",
    "# model development\n",
    "\n",
    "gbm_model_imp = GradientBoostingRegressor()\n",
    "gbm_model_imp.fit(x_train,\n",
    "             y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving model to disk\n",
    "\n",
    "save_pickle_model(gbm_model_imp, os.path.join(\n",
    "    model_path, \"gbm_model_imp.pickle\"), \"wb\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions and scoring\n",
    "\n",
    "gbm_model_imp = load_pickle_model(os.path.join(\n",
    "    model_path, \"gbm_model_imp.pickle\"), \"rb\")\n",
    "\n",
    "gbm_imp_train_predicted = gbm_model_imp.predict(x_train)\n",
    "gbm_imp_score_train = max(0, 100)*r2_score(y_train.values.ravel(), \n",
    "                                      gbm_imp_train_predicted)\n",
    "gbm_imp_val_predicted = gbm_model_imp.predict(x_val)\n",
    "gbm_imp_score_val = max(0, 100)*r2_score(y_val, \n",
    "                                    gbm_imp_val_predicted)\n",
    "\n",
    "# rmse\n",
    "gbm_imp_rmse_train =  round(mean_squared_error(y_train, gbm_imp_train_predicted),2)\n",
    "gbm_imp_rmse_val = round(mean_squared_error(y_val, gbm_imp_val_predicted),2)\n",
    "\n",
    "gbm_imp_metric = {}\n",
    "gbm_imp_metric[\"train\"]={}\n",
    "gbm_imp_metric[\"val\"]={}\n",
    "gbm_imp_metric[\"train\"][\"r2_score\"] = gbm_imp_score_train\n",
    "gbm_imp_metric[\"val\"][\"r2_score\"] = gbm_imp_score_val\n",
    "gbm_imp_metric[\"train\"][\"rmse_train\"] = gbm_imp_rmse_train\n",
    "gbm_imp_metric[\"val\"][\"rmse_val\"] = gbm_imp_rmse_val\n",
    "\n",
    "\n",
    "save_dict_to_json(gbm_imp_metric, os.path.join(\n",
    "    metrics_path, 'gbm_imp_metric.json'), 'w')\n",
    "rf_imp_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### scaling data\n",
    "\n",
    "<br> Scaling is done to Normalize data so that priority is not given to a particular feature. \n",
    "<br> Role of Scaling is mostly important in algorithms that are distance based and require Euclidean Distance. \n",
    "<br> Random Forest is a tree-based model and hence does not require feature scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize x data \n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(x_train)\n",
    "x_train_scaled = scaler.transform(x_train)\n",
    "x_val_scaled = scaler.transform(x_val)\n",
    "# x_test_scaled = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_scaled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model development\n",
    "\n",
    "# params = {'penalty':['l1','l2'],\n",
    "#           'tol':[0.001, 0.0001],\n",
    "#           'alpha': [0.0001, 0.00001],\n",
    "#          'max_iter': [500, 1000, 1500]}\n",
    "\n",
    "ln_model = SGDRegressor(loss='squared_loss')\n",
    "\n",
    "# ln_model = GridSearchCV(model,\n",
    "#                          cv=10,\n",
    "#                          param_grid=params,\n",
    "#                          n_jobs=-1,\n",
    "#                          verbose=5,\n",
    "#                          scoring='neg_mean_absolute_error')\n",
    "ln_model.fit(x_train_scaled, \n",
    "             y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving model to disk\n",
    "\n",
    "save_pickle_model(ln_model, os.path.join(\n",
    "    model_path, \"ln_model.pickle\"), \"wb\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions and scoring\n",
    "\n",
    "linear_train_predicted = ln_model.predict(x_train_scaled)\n",
    "linear_score_train = round(max(0, 100)*r2_score(y_train.values.ravel(), \n",
    "                                          linear_train_predicted),2)\n",
    "linear_val_predicted = ln_model.predict(x_val_scaled)\n",
    "linear_score_val = round(max(0, 100)*r2_score(y_val, \n",
    "                                        linear_val_predicted),2)\n",
    "# rmse\n",
    "linear_rmse_train =  round(mean_squared_error(y_train, linear_train_predicted),2)\n",
    "linear_rmse_val = round(mean_squared_error(y_val, linear_val_predicted),2)\n",
    "\n",
    "linear_metric = {}\n",
    "linear_metric[\"train\"]={}\n",
    "linear_metric[\"val\"]={}\n",
    "linear_metric[\"train\"][\"r2_score\"] = linear_score_train\n",
    "linear_metric[\"val\"][\"r2_score\"] = linear_score_val\n",
    "linear_metric[\"train\"][\"rmse_train\"] = linear_rmse_train\n",
    "linear_metric[\"val\"][\"rmse_val\"] = linear_rmse_val\n",
    "save_dict_to_json(linear_metric, os.path.join(\n",
    "    metrics_path, 'linear_metric.json'), 'w')\n",
    "linear_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vif_drop_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor    \n",
    "\n",
    "def calculate_vif_(X, thresh=5.0):\n",
    "    variables = list(range(X.shape[1]))\n",
    "    dropped = True\n",
    "    while dropped:\n",
    "        dropped = False\n",
    "        vif = [variance_inflation_factor(X.iloc[:, variables].values, ix)\n",
    "               for ix in range(X.iloc[:, variables].shape[1])]\n",
    "\n",
    "        maxloc = vif.index(max(vif))\n",
    "        if max(vif) > thresh:\n",
    "            print('dropping \\'' + X.iloc[:, variables].columns[maxloc] +\n",
    "                  '\\' at index: ' + str(maxloc))\n",
    "            del variables[maxloc]\n",
    "            dropped = True\n",
    "\n",
    "    print('Remaining variables:')\n",
    "    print(X.columns[variables])\n",
    "    return X.iloc[:, variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_vif_(x_train, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vif_keep_col = ['7days_all_gap_days', 'all_gap_7days_last_vs_previous',\n",
    "       '30days_all_gap_days', 'all_gap_30days_last_vs_previous',\n",
    "       'mtd_all_gap_days', 'all_gap_mtd_previous_days', 'all_last_day',\n",
    "       'all_last30_stable', 'all_last30_inc_count', 'all_consistency_index',\n",
    "       'avg_all_gap_days_d1_10', 'avg_all_gap_days_d11_20',\n",
    "       'all_gap_days_d1_10_thisvsprev', 'all_gap_days_d11_20_thisvsprev',\n",
    "       'all_gap_days_d20_31_thisvsprev', 'all_7days_min_thisvs4w',\n",
    "       'all_7days_trend_vs4weeks', 'all_7days_trend_vs10weeks',\n",
    "       'all_7days_vslast_month7days', 'all_7days_max_thisvs10w',\n",
    "       'all_ystrday_vsmin10d', 'all_ystrday_trend_vs10d',\n",
    "       'all_ystrday_vsdaybfr', 'all_mrr_trend_vs6M', 'all_lst30days_vsprvmnth',\n",
    "       'all_mtd_vs_min_lst3M', 'all_trend_mtdvs3M_sameday',\n",
    "       'all_norm_growth_m1', 'all_norm_growth_m2', 'all_norm_growth_m3',\n",
    "       'all_norm_growth_m4', 'all_norm_growth_m5', 'all_norm_growth_m6',\n",
    "       'all_norm_growth_index_last', 'all_gtv_last12Months_m12',\n",
    "       'all_gtv_last10days_d3', 'all_gtv_last10days_d4',\n",
    "       'all_gtv_last10days_d6', 'all_gtv_last10days_d7',\n",
    "       'all_gtv_last10days_d8', 'all_gtv_last10days_d9']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train[vif_keep_col]\n",
    "x_val = x_val[vif_keep_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas_profiling import ProfileReport\n",
    "profile_report = ProfileReport(x_train, title=\"Pandas Profiling Report\")\n",
    "profile_report.to_widgets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_exploration_path = os.path.join(output_path, \"data_exploration\")\n",
    "\n",
    "profile_report.to_file(os.path.join(data_exploration_path, \"profile_report_2__%s.html\"%timestr)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pk_predict = x_test[primary_key]\n",
    "x_predict = x_test.drop([primary_key],1)\n",
    "\n",
    "predicted = rf_model_imp.predict(x_predict)\n",
    "predict_df = pd.DataFrame(predicted, \n",
    "                          columns = [\"Loan Sanction Amount (USD)\"])\n",
    "\n",
    "output_dataframe = pd.merge(x_pk_predict, \n",
    "                            predict_df, \n",
    "                            how=\"left\", \n",
    "                            left_index=True, \n",
    "                            right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dataframe.to_csv(os.path.join(predict_path, \n",
    "                                     \"rf_model_imp__%s.csv\"%timestr),\n",
    "                        index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
